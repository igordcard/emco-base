```
SPDX-License-Identifier: Apache-2.0
Copyright (c) 2019-2020 Intel Corporation
```
# Istio Setup with Emco

When clusters are managed by EMCO, each cluster has its own Istio control plane installated, each managing its own endpoints. All of the clusters are under a shared administrative control of EMCO for the purposes of policy enforcement and security.

A single Istio service mesh across the clusters requires using a common root CA in all of the clusters. Cross-cluster communication occurs over the Istio gateways of the respective clusters.

Setup is similar to https://istio.io/v1.7/docs/setup/install/multicluster/gateways/


## Istio Deployment

Istio installation on all clusters managed by EMCO is pre-requisite. EMCO doesn't install Istio but requires Istio installation on managed clusters as described in this section.

Kubernetes clusters with versions: 1.19.

Downlaod Istio verison: 1.10.3

```
ISTIO_VERSION=1.10.3
curl -L https://istio.io/downloadIstio | ISTIO_VERSION=$ISTIO_VERSION sh -

```


Cross cluster communication requires mutual TLS connection between services. To enable mutual TLS communication across clusters, each clusterâ€™s Istio CA will be configured with intermediate CA credentials generated by a shared root CA.


```
 # Create root certificate
 cd istio-1.10.3/tools/certs
 make -f Makefile.selfsigned.mk ROOT_CN="EMCO Root CA" ROOTCA_ORG=project-emco.io root-ca
 # Create Intermediate CA certs for each cluster
 make -f Makefile.selfsigned.mk INTERMEDIATE_CN="EMCO Intermediate CA" INTERMEDIATE_ORG=project-emco.io cluster1-cacerts

 # Apply secrets on first
 kubectl create secret generic cacerts -n istio-system --from-file=cluster1/ca-cert.pem --from-file=cluster1/ca-key.pem --from-file=cluster1/root-cert.pem --from-file=cluster1/cert-chain.pem

 # Create Intermediate cert for each cluster and create secret per cluster

 ```

### Istio installation

Create configuration file like the example:

```
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: istiooperator-config
  namespace: istio-system
spec:
  profile: minimal
  meshConfig:
    accessLogFile: /dev/stdout
    enableAutoMtls: true
    defaultConfig:
      proxyMetadata:
        # Enable Istio agent to handle DNS
        ISTIO_META_DNS_CAPTURE: "true"
  components:
    # Enable Istio Ingress gateway
    ingressGateways:
    - name: istio-ingressgateway
      enabled: true
      k8s:
        env:
          - name: ISTIO_META_ROUTER_MODE
            value: "sni-dnat"
        service:
          type: NodePort
          ports:
            - port: 80
              targetPort: 8080
              name: http2
            - port: 443
              targetPort: 8443
              name: https
            - port: 15443
              targetPort: 15443
              name: tls
              nodePort: 32001
  values:
    global:
      pilotCertProvider: istiod
```

Install Istio using the above configuration file:
```
 istioctl install  -f istio-config.yaml

```

## EMCO Istio Cross Cluster Configuration

The following sections provides details on the approach followed by EMCO in automating deployment of Istio resources for the resources that requires cross cluster communication. These sections provides example configurations that are used.

### Example configuration with Sleep and httpbin

To demonstrate cross cluster access, configure the sleep service running in one cluster to call the httpbin service running in a second cluster. One cluster is named cluster1 and the other cluster2.

1. Deploy sleep on cluster1

```
    kubectl create namespace foo
    kubectl label  namespace foo istio-injection=enabled
    kubectl apply  -n foo -f samples/sleep/sleep.yaml
    export SLEEP_POD=$(kubectl get -n foo pod -l app=sleep -o jsonpath={.items..metadata.name})

```

2. Deploy httpbin on cluster2

```
kubectl create namespace bar
kubectl label namespace bar istio-injection=enabled
kubectl apply -n bar -f samples/httpbin/httpbin.yaml

```


3. Create service entry for httpbin on cluster1

```
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: httpbin-bar
  namespace: foo
spec:
  hosts:
  # DNS name selected for the service
  - httpbin.bar.cluster2
  # Treat remote cluster services as part of the service mesh
  # as all clusters in the service mesh share the same root of trust.
  location: MESH_INTERNAL
  ports:
  - name: tcp
    number: 8000
    protocol: TCP
  resolution: DNS
  addresses:
  # the IP address to which httpbin.bar.cluster2 will resolve to
  # must be unique for each remote service, within a given cluster.
  # This address need not be routable. Traffic for this IP will be captured
  # by the sidecar and routed appropriately.
  - 240.0.0.2
  endpoints:
  # This is the routable address of the ingress gateway in cluster2 that
  # sits in front of sleep.foo service. Traffic from the sidecar will be
  # routed to this address.
  - address: 192.168.121.10
    ports:
      tcp: 32001 # Nodeport for istio-ingressgateway for port 15433

```
5. Create DestinationRule for httpbin on cluster1

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: httpbin-dr
  namespace: foo
spec:
  host: httpbin.bar.cluster2
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
```

6. On the cluster running httpbin (cluster2) create Gateway resource

```
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: httpbin-gateway
  namespace: istio-system
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15443
        name: tls
        protocol: TLS
      tls:
        mode: AUTO_PASSTHROUGH
      hosts:
        - "httpbin.bar.cluster2"

```

7. Create ServiceEntry on cluster2 that is required to map the remote fqdn to local fqdn:
```
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: httpbin-remote
  namespace: istio-system # must be in same namespace as gateway
spec:
  resolution: DNS
  location: MESH_INTERNAL
  ports:
  - name: tcp
    number: 8000
    protocol: TCP
  exportTo:
  - .
  hosts:
  - "httpbin.bar.cluster2"
  endpoints:
  - address: httpbin.bar.svc.cluster.local

```

8. Create DestinationRule and Virtual Service on cluster2

```
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: httpbin-dr
  namespace: istio-system
spec:
  host: "httpbin.bar.cluster2"
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL

```

9. Verify that httpbin is accessible from the sleep service.

```
 kubectl exec $SLEEP_POD -n foo -c sleep -- curl -I httpbin.bar.cluster2:8000/headers

```

### Configure cross-cluster load balancing

This section will show how to configure Istio route rules to call remote services in a multicluster scenario.


1. Create namespace in both clusters

```
kubectl create namespace sample

```

2. Enable automatic sidecar injection for the sample namespace:

```
kubectl label  namespace sample istio-injection=enabled

```

3. Create the HelloWorld service in both clusters:

```
kubectl apply -f samples/helloworld/helloworld.yaml -l service=helloworld -n sample

```

4. Deploy the helloworld-v1 application to cluster1:

```
kubectl apply -f samples/helloworld/helloworld.yaml -l version=v1 -n sample

```

5. Deploy the helloworld-v2 application to cluster2:

```
kubectl apply -f samples/helloworld/helloworld.yaml -l version=v2 -n sample

```

6. Deploy the Sleep in cluster1:

```
kubectl apply -f samples/sleep/sleep.yaml -n sample

```

7. Apply the following configuration in cluster1:

```
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: hello-dr
  namespace: sample
spec:
  host: helloworld.sample.cluster2
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL

---
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: helloworld-sample
  namespace: sample
spec:
  hosts:
  # DNS name selected for the service
  - helloworld.sample.cluster2
  # Treat remote cluster services as part of the service mesh
  # as all clusters in the service mesh share the same root of trust.
  location: MESH_INTERNAL
  ports:
  - name: tcp
    number: 5000
    protocol: TCP
  resolution: DNS
  addresses:
  # the IP address to which httpbin.bar.cluster2 will resolve to
  # must be unique for each remote service, within a given cluster.
  # This address need not be routable. Traffic for this IP will be captured
  # by the sidecar and routed appropriately.
  - 240.0.0.3
  endpoints:
  # This is the routable address of the ingress gateway in cluster2 that
  # sits in front of sleep.foo service. Traffic from the sidecar will be
  # routed to this address.
  - address: 192.168.121.10
    ports:
      tcp: 32001 # Nodeport for istio-ingressgateway for port 15433
---

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: helloworld
  namespace: sample
spec:
  host: helloworld.sample.svc.cluster.local
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL

---

apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: helloworld
  namespace: sample
spec:
  hosts:
    - helloworld.sample.svc.cluster.local
  http:
  - route:
    - destination:
        host: helloworld.sample.svc.cluster.local
      weight: 50
    - destination:
        host: helloworld.sample.cluster2
      weight: 50

```

8. Apply this configuration on cluster2

```
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: helloworld-gateway
  namespace: istio-system
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 15443
        name: tls
        protocol: TLS
      tls:
        mode: AUTO_PASSTHROUGH
      hosts:
        - "*.sample.cluster2"

---
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: helloworld-remote
  namespace: istio-system # must be in same namespace as gateway
spec:
  resolution: DNS
  location: MESH_INTERNAL
  ports:
  - name: tcp
    number: 5000
    protocol: TLS
  exportTo:
  - .
  hosts:
  - "helloworld.sample.cluster2"
  endpoints:
  - address: helloworld.sample.svc.cluster.local

---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: helloworld-remote
  namespace: istio-system
spec:
  host: "helloworld.sample.cluster2"
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL

```
9. Verify cross-cluster load balancing
To verify that cross-cluster load balancing works as expected, call the HelloWorld service several times using the Sleep pod in cluster1.

```
kubectl exec -n sample -c sleep "$(kubectl get pod -n sample -l app=sleep -o jsonpath='{.items[0].metadata.name}')" -- curl -sS helloworld.sample:5000/hello

```

Repeat this request several times and verify that the HelloWorld version should toggle between v1 and v2:

```
Hello version: v2, instance: helloworld-v2-758dd55874-6x4t8
Hello version: v1, instance: helloworld-v1-86f77cd7bd-cpxhv
```

